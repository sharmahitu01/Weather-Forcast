
# -*- coding: utf-8 -*-
"""weather_dashboard.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ptiul6GNGvNs5DTioKx5RNwgxnPAZ_jO
"""

# -*- coding: utf-8 -*-
"""weather_dashboard_optimized.py"""

# Optimized Weather Forecasting and Dashboard for IIT Mandi

# Import necessary libraries
import os
import numpy as np
import requests
import pandas as pd
from sklearn.ensemble import GradientBoostingClassifier  # Change to Gradient Boosting for potential accuracy gains
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report  # Added classification report for detailed evaluation
from sklearn.preprocessing import LabelEncoder
import streamlit as st
import matplotlib.pyplot as plt
from joblib import dump, load
import seaborn as sns

# Fetch Weather Data
def fetch_weather_data(lat, lon):
    url = f"https://api.open-meteo.com/v1/forecast?latitude={lat}&longitude={lon}&hourly=temperature_2m,relative_humidity_2m,wind_speed_10m,wind_direction_10m,pressure_msl,precipitation,cloudcover&timezone=auto"
    try:
        response = requests.get(url, timeout=10)  # Add timeout for better handling of network issues
        response.raise_for_status()  # Raise an exception for HTTP errors
        data = response.json()["hourly"]
        df = pd.DataFrame(data)
        df.rename(columns={
            "time": "date_time",
            "temperature_2m": "temperature",
            "relative_humidity_2m": "humidity",
            "wind_speed_10m": "wind_speed",
            "wind_direction_10m": "wind_direction",
            "pressure_msl": "pressure",
            "precipitation": "precipitation",
            "cloudcover": "cloud_coverage"
        }, inplace=True)
        df["date_time"] = pd.to_datetime(df["date_time"], errors="coerce")  # Ensure datetime conversion
        return df
    except requests.exceptions.RequestException as e:
        print(f"Error fetching data: {e}")
        return None

# Preprocess Data
def preprocess_data(df):
    df.fillna(df.mean(), inplace=True)  # Handle missing values
    le = LabelEncoder()

    # Derive `weather_condition` and encode
    conditions = np.where(df["precipitation"] > 0, "rainy",
                 np.where(df["cloud_coverage"] > 50, "cloudy", "clear"))  # Simplified conditional logic
    df["weather_condition"] = le.fit_transform(conditions)
    return df, le

# Train Machine Learning Model
def train_model(df):
    X = df.drop(columns=["date_time", "weather_condition"])  # Features
    y = df["weather_condition"]  # Target variable

    # Split data into train/test sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Train Gradient Boosting model
    model = GradientBoostingClassifier()  # Switched from Random Forest to Gradient Boosting
    model.fit(X_train, y_train)

    # Evaluate model accuracy
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    print(f"Model accuracy: {accuracy:.2f}")
    print("Classification Report:")
    print(classification_report(y_test, y_pred))  # Detailed evaluation metrics

    # Save the trained model
    dump(model, "weather_forecast_model_optimized.joblib")
    print("Model saved successfully as weather_forecast_model_optimized.joblib")

    return model

# Save Predictions
def predict_weather(model, df, le):
    try:
        # Decode model predictions
        df["forecasted_weather"] = le.inverse_transform(
            model.predict(df.drop(columns=["date_time", "weather_condition"])))

        # Save to CSV
        output_path = "iit_mandi_weather_optimized.csv"
        df.to_csv(output_path, index=False)
        print(f"Predictions successfully saved to: {output_path}")
    except Exception as e:
        print(f"Error during prediction or saving: {e}")

# Enhanced Visualization: Temperature and Humidity Trends
def visualize_temperature_humidity(data):
    fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(10, 8))

    # Temperature plot
    axes[0].plot(data["date_time"], data["temperature"], label="Temperature (°C)", color="red", linewidth=2)
    axes[0].set_title("Temperature Trend")
    axes[0].set_xlabel("Date Time")
    axes[0].set_ylabel("Temperature (°C)")
    axes[0].legend()

    # Humidity plot
    axes[1].plot(data["date_time"], data["humidity"], label="Humidity (%)", color="blue", linewidth=2)
    axes[1].set_title("Humidity Trend")
    axes[1].set_xlabel("Date Time")
    axes[1].set_ylabel("Humidity (%)")
    axes[1].legend()

    # Display plot
    plt.tight_layout()
    st.pyplot(fig)

# Enhanced Visualization: Forecast Distribution Pie Chart
def visualize_forecast_distribution(data):
    forecast_counts = data["forecasted_weather"].value_counts()

    # Pie chart
    fig, ax = plt.subplots(figsize=(8, 6))
    ax.pie(forecast_counts, labels=forecast_counts.index, autopct='%1.1f%%', startangle=90, colors=["red", "blue", "green"])
    ax.set_title("Forecasted Weather Distribution")

    # Display chart
    st.pyplot(fig)

# Enhanced Visualization: Correlation Heatmap
def visualize_correlation(data):
    correlation_matrix = data[["temperature", "humidity", "wind_speed", "pressure"]].corr()

    # Heatmap
    fig, ax = plt.subplots(figsize=(10, 8))
    sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm", ax=ax)
    ax.set_title("Correlation Heatmap of Weather Variables")

    # Display heatmap
    st.pyplot(fig)

# Streamlit Dashboard
def run_dashboard():
    @st.cache_data  # Cache the data loading to improve performance
    def load_data():
        # Load the CSV file - adjust path if needed
        data = pd.read_csv("iit_mandi_weather_optimized.csv")
        data["date_time"] = pd.to_datetime(data["date_time"])
        return data

    data = load_data()

    # Streamlit App
    st.title("Weather Forecast Dashboard for IIT Mandi")
    st.subheader("Visualizing Historical Trends and Predictions")

    # Visualize Temperature and Humidity Trends
    st.write("### Temperature and Humidity Trends")
    visualize_temperature_humidity(data)

    # Visualize Forecasted Weather Distribution
    st.write("### Forecast Distribution")
    visualize_forecast_distribution(data)

    # Visualize Correlations
    st.write("### Correlation Heatmap")
    visualize_correlation(data)

# Main Execution
if __name__ == "__main__":
    latitude = 31.7744
    longitude = 76.9849

    # Check if running in Streamlit using st.runtime.exists()
    if not st.runtime.exists():  # Use the public st.runtime.exists() method
        print("Fetching initial data for IIT Mandi...")
        weather_data = fetch_weather_data(latitude, longitude)
        if weather_data is not None:
            print("Sample data fetched:")
            print(weather_data.head())

            print("Preprocessing initial data...")
            weather_data, le = preprocess_data(weather_data)
            print("Training initial model...")
            model = train_model(weather_data)
            predict_weather(model, weather_data, le)  # Ensure CSV is created

    # Run the dashboard when running in Streamlit
    run_dashboard()

